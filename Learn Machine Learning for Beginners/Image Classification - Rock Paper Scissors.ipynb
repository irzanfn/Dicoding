{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Akhir_Dicoding_Irzan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PvqmvBMfgyP"
      },
      "source": [
        "# Image Classification Rock Paper Scissors\n",
        "# Irzan Fajari Nurahmadan \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiV3KbT6kz-7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q9TkWnCfpX6"
      },
      "source": [
        "#Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQWkv0Xs4pnG"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkWsa5RpfoVN"
      },
      "source": [
        "#Download Dataset RockPaperScissors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwzIQmBA5ASv",
        "outputId": "52a69876-7c20-4c76-c1f9-60929f635a73"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-05 07:51:26--  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210905%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210905T075126Z&X-Amz-Expires=300&X-Amz-Signature=7ed86af8b7592876bcc5395042c36da20e5edce16bc0961812ff76534e434acb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-09-05 07:51:26--  https://github-releases.githubusercontent.com/391417272/7eb836f2-695b-4a46-9c78-b65867166957?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210905%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210905T075126Z&X-Amz-Expires=300&X-Amz-Signature=7ed86af8b7592876bcc5395042c36da20e5edce16bc0961812ff76534e434acb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=391417272&response-content-disposition=attachment%3B%20filename%3Drockpaperscissors.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.109.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322873683 (308M) [application/octet-stream]\n",
            "Saving to: ‘rockpaperscissors.zip’\n",
            "\n",
            "rockpaperscissors.z 100%[===================>] 307.92M  45.1MB/s    in 6.7s    \n",
            "\n",
            "2021-09-05 07:51:33 (46.0 MB/s) - ‘rockpaperscissors.zip’ saved [322873683/322873683]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpYSLUArf2xc"
      },
      "source": [
        "#Extract Dataset RockPaperScissors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk2zHMIO5BFY",
        "outputId": "82873627-ee5c-437a-c415-69e3ae779b08"
      },
      "source": [
        "#melakukan ekstraksi pada file zip\n",
        "local_zip = '/content/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "os.listdir('/tmp/rockpaperscissors')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rock', 'rps-cv-images', 'scissors', 'paper', 'README_rpc-cv-images.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWu3XAO75fyx"
      },
      "source": [
        "DATADIR = \"/tmp/rockpaperscissors/rps-cv-images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C8yH3pgf75Z"
      },
      "source": [
        "#Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAmWODjkU2bM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyvoqnEs5YH2",
        "outputId": "dd0a3fb3-87d3-42dc-d6e2-9d08caca66fa"
      },
      "source": [
        "augment_datagen = ImageDataGenerator( \n",
        "    rescale = 1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip = True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.4\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = augment_datagen.flow_from_directory(\n",
        "    DATADIR,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150),\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = augment_datagen.flow_from_directory(\n",
        "    DATADIR,\n",
        "    class_mode='categorical',\n",
        "    target_size=(150, 150),\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1314 images belonging to 3 classes.\n",
            "Found 874 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1-wwyzgf_qJ"
      },
      "source": [
        "#Making Based Sequential CNN Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz5587m65hq7",
        "outputId": "601bd81b-32f9-43c3-b251-b1c1e43b9bfd"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_282 (Conv2D)          (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_283 (Conv2D)          (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_284 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_285 (Conv2D)          (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               6423040   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 6,812,995\n",
            "Trainable params: 6,812,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoWHGpbpgGld"
      },
      "source": [
        "#Callback To Control Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGRsEZwo5kTc"
      },
      "source": [
        "best = './base.model'\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    best,\n",
        "    monitor='loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    save_weights_only=False,\n",
        "    save_freq=1\n",
        ")\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    min_delta=0.001,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "\n",
        "callbacks = [checkpoint,earlystop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvDY9qHXgIpq"
      },
      "source": [
        "#Compile The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwTPhyZn5tJf"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD3KLPpkgKxi"
      },
      "source": [
        "#Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2n14kUY5x2t",
        "outputId": "07785626-1e54-427e-8580-8924c76020e4"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "      epochs=20, # tambahkan eposchs jika akurasi model belum optimal\n",
        "      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi\n",
        "      validation_steps=5,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "      verbose=1,\n",
        "      callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 1/25 [>.............................] - ETA: 1:20 - loss: 1.1010 - accuracy: 0.3438\n",
            "Epoch 00001: loss improved from inf to 1.10098, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:11 - loss: 1.1706 - accuracy: 0.3125\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            " 3/25 [==>...........................] - ETA: 53s - loss: 1.1872 - accuracy: 0.2951 \n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            " 4/25 [===>..........................] - ETA: 45s - loss: 1.1871 - accuracy: 0.2936\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            " 5/25 [=====>........................] - ETA: 41s - loss: 1.1835 - accuracy: 0.2974\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            " 6/25 [======>.......................] - ETA: 38s - loss: 1.1786 - accuracy: 0.3051\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            " 7/25 [=======>......................] - ETA: 35s - loss: 1.1735 - accuracy: 0.3126\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            " 8/25 [========>.....................] - ETA: 32s - loss: 1.1700 - accuracy: 0.3169\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            " 9/25 [=========>....................] - ETA: 30s - loss: 1.1670 - accuracy: 0.3195\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "10/25 [===========>..................] - ETA: 28s - loss: 1.1643 - accuracy: 0.3204\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "11/25 [============>.................] - ETA: 26s - loss: 1.1617 - accuracy: 0.3228\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "12/25 [=============>................] - ETA: 24s - loss: 1.1592 - accuracy: 0.3245\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "13/25 [==============>...............] - ETA: 22s - loss: 1.1569 - accuracy: 0.3262\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "14/25 [===============>..............] - ETA: 20s - loss: 1.1547 - accuracy: 0.3273\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "15/25 [=================>............] - ETA: 18s - loss: 1.1527 - accuracy: 0.3295\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "16/25 [==================>...........] - ETA: 16s - loss: 1.1508 - accuracy: 0.3318\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 1.1491 - accuracy: 0.3340\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 1.1474 - accuracy: 0.3363\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "19/25 [=====================>........] - ETA: 11s - loss: 1.1458 - accuracy: 0.3387\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "20/25 [=======================>......] - ETA: 9s - loss: 1.1442 - accuracy: 0.3410 \n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "21/25 [========================>.....] - ETA: 7s - loss: 1.1428 - accuracy: 0.3428\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 1.1415 - accuracy: 0.3442\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 1.1402 - accuracy: 0.3456\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 1.1389 - accuracy: 0.3471\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1377 - accuracy: 0.3486\n",
            "Epoch 00001: loss did not improve from 1.10098\n",
            "25/25 [==============================] - 51s 2s/step - loss: 1.1365 - accuracy: 0.3500 - val_loss: 1.1379 - val_accuracy: 0.3500\n",
            "Epoch 2/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 1.1073 - accuracy: 0.3125\n",
            "Epoch 00002: loss did not improve from 1.10098\n",
            " 2/25 [=>............................] - ETA: 39s - loss: 1.1044 - accuracy: 0.3203\n",
            "Epoch 00002: loss did not improve from 1.10098\n",
            " 3/25 [==>...........................] - ETA: 37s - loss: 1.0926 - accuracy: 0.3524\n",
            "Epoch 00002: loss improved from 1.10098 to 1.06890, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 4/25 [===>..........................] - ETA: 45s - loss: 1.0882 - accuracy: 0.3639\n",
            "Epoch 00002: loss did not improve from 1.06890\n",
            " 5/25 [=====>........................] - ETA: 41s - loss: 1.0825 - accuracy: 0.3774\n",
            "Epoch 00002: loss improved from 1.06890 to 1.05962, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 6/25 [======>.......................] - ETA: 42s - loss: 1.0787 - accuracy: 0.3857\n",
            "Epoch 00002: loss did not improve from 1.05962\n",
            " 7/25 [=======>......................] - ETA: 38s - loss: 1.0751 - accuracy: 0.3918\n",
            "Epoch 00002: loss improved from 1.05962 to 1.05369, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 8/25 [========>.....................] - ETA: 39s - loss: 1.0726 - accuracy: 0.3970\n",
            "Epoch 00002: loss did not improve from 1.05369\n",
            " 9/25 [=========>....................] - ETA: 35s - loss: 1.0694 - accuracy: 0.4023\n",
            "Epoch 00002: loss improved from 1.05369 to 1.04385, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "10/25 [===========>..................] - ETA: 35s - loss: 1.0668 - accuracy: 0.4061\n",
            "Epoch 00002: loss improved from 1.04385 to 1.04289, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "11/25 [============>.................] - ETA: 33s - loss: 1.0634 - accuracy: 0.4108\n",
            "Epoch 00002: loss improved from 1.04289 to 1.03008, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "12/25 [=============>................] - ETA: 32s - loss: 1.0598 - accuracy: 0.4156\n",
            "Epoch 00002: loss improved from 1.03008 to 1.02046, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "13/25 [==============>...............] - ETA: 30s - loss: 1.0563 - accuracy: 0.4197\n",
            "Epoch 00002: loss improved from 1.02046 to 1.01373, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "14/25 [===============>..............] - ETA: 29s - loss: 1.0528 - accuracy: 0.4240\n",
            "Epoch 00002: loss improved from 1.01373 to 1.00755, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "15/25 [=================>............] - ETA: 27s - loss: 1.0496 - accuracy: 0.4282\n",
            "Epoch 00002: loss improved from 1.00755 to 1.00414, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "16/25 [==================>...........] - ETA: 24s - loss: 1.0474 - accuracy: 0.4316\n",
            "Epoch 00002: loss did not improve from 1.00414\n",
            "17/25 [===================>..........] - ETA: 21s - loss: 1.0454 - accuracy: 0.4349\n",
            "Epoch 00002: loss did not improve from 1.00414\n",
            "18/25 [====================>.........] - ETA: 18s - loss: 1.0440 - accuracy: 0.4374\n",
            "Epoch 00002: loss did not improve from 1.00414\n",
            "19/25 [=====================>........] - ETA: 15s - loss: 1.0426 - accuracy: 0.4399\n",
            "Epoch 00002: loss did not improve from 1.00414\n",
            "20/25 [=======================>......] - ETA: 12s - loss: 1.0411 - accuracy: 0.4423\n",
            "Epoch 00002: loss did not improve from 1.00414\n",
            "21/25 [========================>.....] - ETA: 9s - loss: 1.0395 - accuracy: 0.4449 \n",
            "Epoch 00002: loss did not improve from 1.00414\n",
            "22/25 [=========================>....] - ETA: 7s - loss: 1.0377 - accuracy: 0.4477\n",
            "Epoch 00002: loss improved from 1.00414 to 1.00021, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "23/25 [==========================>...] - ETA: 4s - loss: 1.0360 - accuracy: 0.4503\n",
            "Epoch 00002: loss improved from 1.00021 to 0.99900, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "24/25 [===========================>..] - ETA: 2s - loss: 1.0346 - accuracy: 0.4526\n",
            "Epoch 00002: loss did not improve from 0.99900\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0332 - accuracy: 0.4547\n",
            "Epoch 00002: loss did not improve from 0.99900\n",
            "25/25 [==============================] - 64s 3s/step - loss: 1.0319 - accuracy: 0.4566 - val_loss: 0.8927 - val_accuracy: 0.5375\n",
            "Epoch 3/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.9084 - accuracy: 0.5625\n",
            "Epoch 00003: loss improved from 0.99900 to 0.90840, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:10 - loss: 0.9515 - accuracy: 0.5078\n",
            "Epoch 00003: loss did not improve from 0.90840\n",
            " 3/25 [==>...........................] - ETA: 52s - loss: 0.9524 - accuracy: 0.5017 \n",
            "Epoch 00003: loss did not improve from 0.90840\n",
            " 4/25 [===>..........................] - ETA: 45s - loss: 0.9520 - accuracy: 0.5052\n",
            "Epoch 00003: loss did not improve from 0.90840\n",
            " 5/25 [=====>........................] - ETA: 40s - loss: 0.9467 - accuracy: 0.5167\n",
            "Epoch 00003: loss did not improve from 0.90840\n",
            " 6/25 [======>.......................] - ETA: 37s - loss: 0.9426 - accuracy: 0.5252\n",
            "Epoch 00003: loss did not improve from 0.90840\n",
            " 7/25 [=======>......................] - ETA: 34s - loss: 0.9344 - accuracy: 0.5343\n",
            "Epoch 00003: loss improved from 0.90840 to 0.88555, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 8/25 [========>.....................] - ETA: 35s - loss: 0.9305 - accuracy: 0.5393\n",
            "Epoch 00003: loss did not improve from 0.88555\n",
            " 9/25 [=========>....................] - ETA: 33s - loss: 0.9264 - accuracy: 0.5450\n",
            "Epoch 00003: loss did not improve from 0.88555\n",
            "10/25 [===========>..................] - ETA: 31s - loss: 0.9197 - accuracy: 0.5524\n",
            "Epoch 00003: loss improved from 0.88555 to 0.85958, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "11/25 [============>.................] - ETA: 30s - loss: 0.9153 - accuracy: 0.5582\n",
            "Epoch 00003: loss did not improve from 0.85958\n",
            "12/25 [=============>................] - ETA: 28s - loss: 0.9110 - accuracy: 0.5629\n",
            "Epoch 00003: loss did not improve from 0.85958\n",
            "13/25 [==============>...............] - ETA: 25s - loss: 0.9065 - accuracy: 0.5673\n",
            "Epoch 00003: loss improved from 0.85958 to 0.85361, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "14/25 [===============>..............] - ETA: 24s - loss: 0.9020 - accuracy: 0.5717\n",
            "Epoch 00003: loss improved from 0.85361 to 0.84231, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "15/25 [=================>............] - ETA: 23s - loss: 0.8968 - accuracy: 0.5763\n",
            "Epoch 00003: loss improved from 0.84231 to 0.82391, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "16/25 [==================>...........] - ETA: 23s - loss: 0.8936 - accuracy: 0.5797\n",
            "Epoch 00003: loss did not improve from 0.82391\n",
            "17/25 [===================>..........] - ETA: 20s - loss: 0.8904 - accuracy: 0.5831\n",
            "Epoch 00003: loss did not improve from 0.82391\n",
            "18/25 [====================>.........] - ETA: 18s - loss: 0.8875 - accuracy: 0.5863\n",
            "Epoch 00003: loss did not improve from 0.82391\n",
            "19/25 [=====================>........] - ETA: 16s - loss: 0.8842 - accuracy: 0.5896\n",
            "Epoch 00003: loss did not improve from 0.82391\n",
            "20/25 [=======================>......] - ETA: 13s - loss: 0.8813 - accuracy: 0.5926\n",
            "Epoch 00003: loss did not improve from 0.82391\n",
            "21/25 [========================>.....] - ETA: 10s - loss: 0.8783 - accuracy: 0.5955\n",
            "Epoch 00003: loss improved from 0.82391 to 0.81828, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "22/25 [=========================>....] - ETA: 7s - loss: 0.8752 - accuracy: 0.5983 \n",
            "Epoch 00003: loss improved from 0.81828 to 0.80888, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "23/25 [==========================>...] - ETA: 5s - loss: 0.8718 - accuracy: 0.6011\n",
            "Epoch 00003: loss improved from 0.80888 to 0.79783, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "24/25 [===========================>..] - ETA: 2s - loss: 0.8685 - accuracy: 0.6038\n",
            "Epoch 00003: loss improved from 0.79783 to 0.79149, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8649 - accuracy: 0.6065\n",
            "Epoch 00003: loss improved from 0.79149 to 0.78004, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "25/25 [==============================] - 73s 3s/step - loss: 0.8617 - accuracy: 0.6090 - val_loss: 0.4804 - val_accuracy: 0.8375\n",
            "Epoch 4/20\n",
            " 1/25 [>.............................] - ETA: 51s - loss: 0.4907 - accuracy: 0.7500\n",
            "Epoch 00004: loss improved from 0.78004 to 0.49075, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:23 - loss: 0.5210 - accuracy: 0.7500\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            " 3/25 [==>...........................] - ETA: 58s - loss: 0.5617 - accuracy: 0.7396 \n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            " 4/25 [===>..........................] - ETA: 50s - loss: 0.5701 - accuracy: 0.7422\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            " 5/25 [=====>........................] - ETA: 44s - loss: 0.5783 - accuracy: 0.7425\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            " 6/25 [======>.......................] - ETA: 39s - loss: 0.5865 - accuracy: 0.7420\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            " 7/25 [=======>......................] - ETA: 36s - loss: 0.5882 - accuracy: 0.7451\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            " 8/25 [========>.....................] - ETA: 34s - loss: 0.5857 - accuracy: 0.7496\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            " 9/25 [=========>....................] - ETA: 31s - loss: 0.5831 - accuracy: 0.7547\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "10/25 [===========>..................] - ETA: 29s - loss: 0.5804 - accuracy: 0.7586\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "11/25 [============>.................] - ETA: 26s - loss: 0.5777 - accuracy: 0.7617\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "12/25 [=============>................] - ETA: 24s - loss: 0.5748 - accuracy: 0.7639\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "13/25 [==============>...............] - ETA: 22s - loss: 0.5715 - accuracy: 0.7662\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "14/25 [===============>..............] - ETA: 20s - loss: 0.5688 - accuracy: 0.7685\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "15/25 [=================>............] - ETA: 18s - loss: 0.5659 - accuracy: 0.7709\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "16/25 [==================>...........] - ETA: 16s - loss: 0.5635 - accuracy: 0.7730\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 0.5614 - accuracy: 0.7748\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.5591 - accuracy: 0.7764\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.5564 - accuracy: 0.7782\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "20/25 [=======================>......] - ETA: 9s - loss: 0.5546 - accuracy: 0.7794 \n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "21/25 [========================>.....] - ETA: 7s - loss: 0.5533 - accuracy: 0.7803\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.5518 - accuracy: 0.7814\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.5503 - accuracy: 0.7825\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.5493 - accuracy: 0.7834\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.7841\n",
            "Epoch 00004: loss did not improve from 0.49075\n",
            "25/25 [==============================] - 49s 2s/step - loss: 0.5477 - accuracy: 0.7848 - val_loss: 0.5216 - val_accuracy: 0.8188\n",
            "Epoch 5/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.4108 - accuracy: 0.8125\n",
            "Epoch 00005: loss improved from 0.49075 to 0.41081, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:12 - loss: 0.4870 - accuracy: 0.7578\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            " 3/25 [==>...........................] - ETA: 53s - loss: 0.5094 - accuracy: 0.7448 \n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            " 4/25 [===>..........................] - ETA: 45s - loss: 0.5012 - accuracy: 0.7500\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            " 5/25 [=====>........................] - ETA: 41s - loss: 0.4930 - accuracy: 0.7562\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            " 6/25 [======>.......................] - ETA: 37s - loss: 0.4896 - accuracy: 0.7578\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            " 7/25 [=======>......................] - ETA: 34s - loss: 0.4955 - accuracy: 0.7580\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            " 8/25 [========>.....................] - ETA: 32s - loss: 0.5015 - accuracy: 0.7594\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            " 9/25 [=========>....................] - ETA: 31s - loss: 0.5066 - accuracy: 0.7607\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "10/25 [===========>..................] - ETA: 29s - loss: 0.5097 - accuracy: 0.7618\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "11/25 [============>.................] - ETA: 26s - loss: 0.5121 - accuracy: 0.7628\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "12/25 [=============>................] - ETA: 24s - loss: 0.5121 - accuracy: 0.7648\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "13/25 [==============>...............] - ETA: 22s - loss: 0.5114 - accuracy: 0.7664\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "14/25 [===============>..............] - ETA: 19s - loss: 0.5108 - accuracy: 0.7679\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "15/25 [=================>............] - ETA: 17s - loss: 0.5100 - accuracy: 0.7694\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.5092 - accuracy: 0.7707\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 0.5083 - accuracy: 0.7720\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.5073 - accuracy: 0.7732\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.5063 - accuracy: 0.7745\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.5054 - accuracy: 0.7760 \n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.5048 - accuracy: 0.7774\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.5040 - accuracy: 0.7788\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.5034 - accuracy: 0.7802\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.5030 - accuracy: 0.7814\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.7826\n",
            "Epoch 00005: loss did not improve from 0.41081\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.5021 - accuracy: 0.7837 - val_loss: 0.3137 - val_accuracy: 0.9062\n",
            "Epoch 6/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.2795 - accuracy: 0.8750\n",
            "Epoch 00006: loss improved from 0.41081 to 0.27951, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:11 - loss: 0.3000 - accuracy: 0.8594\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            " 3/25 [==>...........................] - ETA: 52s - loss: 0.3000 - accuracy: 0.8646 \n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            " 4/25 [===>..........................] - ETA: 45s - loss: 0.3144 - accuracy: 0.8574\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            " 5/25 [=====>........................] - ETA: 40s - loss: 0.3196 - accuracy: 0.8547\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            " 6/25 [======>.......................] - ETA: 37s - loss: 0.3272 - accuracy: 0.8520\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            " 7/25 [=======>......................] - ETA: 36s - loss: 0.3371 - accuracy: 0.8495\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            " 8/25 [========>.....................] - ETA: 33s - loss: 0.3432 - accuracy: 0.8483\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            " 9/25 [=========>....................] - ETA: 31s - loss: 0.3455 - accuracy: 0.8486\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "10/25 [===========>..................] - ETA: 29s - loss: 0.3474 - accuracy: 0.8490\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "11/25 [============>.................] - ETA: 26s - loss: 0.3474 - accuracy: 0.8504\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "12/25 [=============>................] - ETA: 24s - loss: 0.3464 - accuracy: 0.8518\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "13/25 [==============>...............] - ETA: 22s - loss: 0.3457 - accuracy: 0.8532\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "14/25 [===============>..............] - ETA: 20s - loss: 0.3448 - accuracy: 0.8547\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "15/25 [=================>............] - ETA: 18s - loss: 0.3434 - accuracy: 0.8564\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "16/25 [==================>...........] - ETA: 16s - loss: 0.3422 - accuracy: 0.8579\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 0.3414 - accuracy: 0.8591\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.3400 - accuracy: 0.8605\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.3384 - accuracy: 0.8617\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "20/25 [=======================>......] - ETA: 9s - loss: 0.3367 - accuracy: 0.8628 \n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "21/25 [========================>.....] - ETA: 7s - loss: 0.3350 - accuracy: 0.8640\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.3333 - accuracy: 0.8652\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.3316 - accuracy: 0.8664\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.3302 - accuracy: 0.8674\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.8685\n",
            "Epoch 00006: loss did not improve from 0.27951\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.3271 - accuracy: 0.8694 - val_loss: 0.4242 - val_accuracy: 0.8625\n",
            "Epoch 7/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.2968 - accuracy: 0.9375\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 2/25 [=>............................] - ETA: 39s - loss: 0.5496 - accuracy: 0.8594\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 3/25 [==>...........................] - ETA: 37s - loss: 0.5899 - accuracy: 0.8507\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 4/25 [===>..........................] - ETA: 35s - loss: 0.5840 - accuracy: 0.8470\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 5/25 [=====>........................] - ETA: 33s - loss: 0.5613 - accuracy: 0.8501\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 6/25 [======>.......................] - ETA: 32s - loss: 0.5459 - accuracy: 0.8499\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 7/25 [=======>......................] - ETA: 29s - loss: 0.5358 - accuracy: 0.8490\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 8/25 [========>.....................] - ETA: 24s - loss: 0.5278 - accuracy: 0.8485\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            " 9/25 [=========>....................] - ETA: 24s - loss: 0.5186 - accuracy: 0.8490\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "10/25 [===========>..................] - ETA: 22s - loss: 0.5099 - accuracy: 0.8496\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "11/25 [============>.................] - ETA: 21s - loss: 0.5037 - accuracy: 0.8497\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "12/25 [=============>................] - ETA: 20s - loss: 0.4970 - accuracy: 0.8505\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "13/25 [==============>...............] - ETA: 18s - loss: 0.4910 - accuracy: 0.8512\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "14/25 [===============>..............] - ETA: 17s - loss: 0.4857 - accuracy: 0.8516\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "15/25 [=================>............] - ETA: 15s - loss: 0.4796 - accuracy: 0.8525\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "16/25 [==================>...........] - ETA: 14s - loss: 0.4732 - accuracy: 0.8536\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "17/25 [===================>..........] - ETA: 12s - loss: 0.4676 - accuracy: 0.8547\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "18/25 [====================>.........] - ETA: 11s - loss: 0.4630 - accuracy: 0.8555\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "19/25 [=====================>........] - ETA: 9s - loss: 0.4591 - accuracy: 0.8560 \n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.4550 - accuracy: 0.8567\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.4508 - accuracy: 0.8574\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "22/25 [=========================>....] - ETA: 4s - loss: 0.4466 - accuracy: 0.8582\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.4423 - accuracy: 0.8592\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.4382 - accuracy: 0.8601\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.8609\n",
            "Epoch 00007: loss did not improve from 0.27951\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.4307 - accuracy: 0.8616 - val_loss: 0.1612 - val_accuracy: 0.9625\n",
            "Epoch 8/20\n",
            " 1/25 [>.............................] - ETA: 48s - loss: 0.5988 - accuracy: 0.8125\n",
            "Epoch 00008: loss did not improve from 0.27951\n",
            " 2/25 [=>............................] - ETA: 38s - loss: 0.5471 - accuracy: 0.8359\n",
            "Epoch 00008: loss did not improve from 0.27951\n",
            " 3/25 [==>...........................] - ETA: 38s - loss: 0.4929 - accuracy: 0.8559\n",
            "Epoch 00008: loss did not improve from 0.27951\n",
            " 4/25 [===>..........................] - ETA: 36s - loss: 0.4536 - accuracy: 0.8665\n",
            "Epoch 00008: loss did not improve from 0.27951\n",
            " 5/25 [=====>........................] - ETA: 34s - loss: 0.4286 - accuracy: 0.8707\n",
            "Epoch 00008: loss did not improve from 0.27951\n",
            " 6/25 [======>.......................] - ETA: 32s - loss: 0.4095 - accuracy: 0.8749\n",
            "Epoch 00008: loss did not improve from 0.27951\n",
            " 7/25 [=======>......................] - ETA: 30s - loss: 0.3906 - accuracy: 0.8800\n",
            "Epoch 00008: loss improved from 0.27951 to 0.27724, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 8/25 [========>.....................] - ETA: 32s - loss: 0.3738 - accuracy: 0.8848\n",
            "Epoch 00008: loss improved from 0.27724 to 0.25606, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 9/25 [=========>....................] - ETA: 32s - loss: 0.3620 - accuracy: 0.8875\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "10/25 [===========>..................] - ETA: 30s - loss: 0.3533 - accuracy: 0.8894\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "11/25 [============>.................] - ETA: 27s - loss: 0.3452 - accuracy: 0.8915\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "12/25 [=============>................] - ETA: 25s - loss: 0.3390 - accuracy: 0.8929\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "13/25 [==============>...............] - ETA: 23s - loss: 0.3326 - accuracy: 0.8945\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "14/25 [===============>..............] - ETA: 21s - loss: 0.3277 - accuracy: 0.8955\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "15/25 [=================>............] - ETA: 18s - loss: 0.3239 - accuracy: 0.8965\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "16/25 [==================>...........] - ETA: 16s - loss: 0.3204 - accuracy: 0.8975\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 0.3170 - accuracy: 0.8984\n",
            "Epoch 00008: loss did not improve from 0.25606\n",
            "18/25 [====================>.........] - ETA: 13s - loss: 0.3135 - accuracy: 0.8993\n",
            "Epoch 00008: loss improved from 0.25606 to 0.25358, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "19/25 [=====================>........] - ETA: 11s - loss: 0.3100 - accuracy: 0.9003\n",
            "Epoch 00008: loss improved from 0.25358 to 0.24864, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "20/25 [=======================>......] - ETA: 10s - loss: 0.3071 - accuracy: 0.9009\n",
            "Epoch 00008: loss did not improve from 0.24864\n",
            "21/25 [========================>.....] - ETA: 8s - loss: 0.3044 - accuracy: 0.9014 \n",
            "Epoch 00008: loss did not improve from 0.24864\n",
            "22/25 [=========================>....] - ETA: 6s - loss: 0.3018 - accuracy: 0.9021\n",
            "Epoch 00008: loss improved from 0.24864 to 0.24795, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "23/25 [==========================>...] - ETA: 4s - loss: 0.2991 - accuracy: 0.9028\n",
            "Epoch 00008: loss improved from 0.24795 to 0.23983, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "24/25 [===========================>..] - ETA: 2s - loss: 0.2965 - accuracy: 0.9034\n",
            "Epoch 00008: loss improved from 0.23983 to 0.23713, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2939 - accuracy: 0.9041\n",
            "Epoch 00008: loss improved from 0.23713 to 0.22990, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.2914 - accuracy: 0.9048 - val_loss: 0.2028 - val_accuracy: 0.9312\n",
            "Epoch 9/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.1377 - accuracy: 0.9688\n",
            "Epoch 00009: loss improved from 0.22990 to 0.13768, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:10 - loss: 0.1486 - accuracy: 0.9531\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            " 3/25 [==>...........................] - ETA: 52s - loss: 0.1692 - accuracy: 0.9479 \n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            " 4/25 [===>..........................] - ETA: 45s - loss: 0.1807 - accuracy: 0.9453\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            " 5/25 [=====>........................] - ETA: 40s - loss: 0.1860 - accuracy: 0.9450\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            " 6/25 [======>.......................] - ETA: 37s - loss: 0.1886 - accuracy: 0.9455\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            " 7/25 [=======>......................] - ETA: 34s - loss: 0.1915 - accuracy: 0.9443\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            " 8/25 [========>.....................] - ETA: 32s - loss: 0.1923 - accuracy: 0.9440\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            " 9/25 [=========>....................] - ETA: 29s - loss: 0.1915 - accuracy: 0.9440\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "10/25 [===========>..................] - ETA: 27s - loss: 0.1891 - accuracy: 0.9446\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "11/25 [============>.................] - ETA: 25s - loss: 0.1877 - accuracy: 0.9445\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "12/25 [=============>................] - ETA: 23s - loss: 0.1881 - accuracy: 0.9439\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "13/25 [==============>...............] - ETA: 21s - loss: 0.1890 - accuracy: 0.9432\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "14/25 [===============>..............] - ETA: 19s - loss: 0.1897 - accuracy: 0.9428\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "15/25 [=================>............] - ETA: 17s - loss: 0.1897 - accuracy: 0.9427\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.1891 - accuracy: 0.9429\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 0.1889 - accuracy: 0.9428\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.1887 - accuracy: 0.9427\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.1885 - accuracy: 0.9426\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.1880 - accuracy: 0.9425 \n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "21/25 [========================>.....] - ETA: 7s - loss: 0.1878 - accuracy: 0.9423\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1873 - accuracy: 0.9423\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1867 - accuracy: 0.9423\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1863 - accuracy: 0.9423\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1859 - accuracy: 0.9423\n",
            "Epoch 00009: loss did not improve from 0.13768\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.1856 - accuracy: 0.9422 - val_loss: 0.2549 - val_accuracy: 0.9250\n",
            "Epoch 10/20\n",
            " 1/25 [>.............................] - ETA: 45s - loss: 0.1955 - accuracy: 0.9688\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 2/25 [=>............................] - ETA: 53s - loss: 0.1949 - accuracy: 0.9688\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 3/25 [==>...........................] - ETA: 44s - loss: 0.1910 - accuracy: 0.9688\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 4/25 [===>..........................] - ETA: 40s - loss: 0.1870 - accuracy: 0.9668\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 5/25 [=====>........................] - ETA: 36s - loss: 0.1931 - accuracy: 0.9634\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 6/25 [======>.......................] - ETA: 28s - loss: 0.1970 - accuracy: 0.9613\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 7/25 [=======>......................] - ETA: 28s - loss: 0.1969 - accuracy: 0.9602\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 8/25 [========>.....................] - ETA: 27s - loss: 0.1961 - accuracy: 0.9591\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            " 9/25 [=========>....................] - ETA: 25s - loss: 0.1945 - accuracy: 0.9580\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "10/25 [===========>..................] - ETA: 24s - loss: 0.1933 - accuracy: 0.9567\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "11/25 [============>.................] - ETA: 22s - loss: 0.1912 - accuracy: 0.9561\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "12/25 [=============>................] - ETA: 21s - loss: 0.1893 - accuracy: 0.9556\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "13/25 [==============>...............] - ETA: 19s - loss: 0.1869 - accuracy: 0.9554\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "14/25 [===============>..............] - ETA: 17s - loss: 0.1845 - accuracy: 0.9553\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "15/25 [=================>............] - ETA: 16s - loss: 0.1822 - accuracy: 0.9552\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "16/25 [==================>...........] - ETA: 14s - loss: 0.1799 - accuracy: 0.9553\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "17/25 [===================>..........] - ETA: 13s - loss: 0.1786 - accuracy: 0.9550\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "18/25 [====================>.........] - ETA: 11s - loss: 0.1770 - accuracy: 0.9550\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "19/25 [=====================>........] - ETA: 9s - loss: 0.1752 - accuracy: 0.9550 \n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.1734 - accuracy: 0.9551\n",
            "Epoch 00010: loss did not improve from 0.13768\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.1717 - accuracy: 0.9552\n",
            "Epoch 00010: loss improved from 0.13768 to 0.13740, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1701 - accuracy: 0.9552\n",
            "Epoch 00010: loss improved from 0.13740 to 0.13565, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1684 - accuracy: 0.9552\n",
            "Epoch 00010: loss improved from 0.13565 to 0.13210, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1667 - accuracy: 0.9553\n",
            "Epoch 00010: loss improved from 0.13210 to 0.12714, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9555\n",
            "Epoch 00010: loss improved from 0.12714 to 0.12258, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            "25/25 [==============================] - 52s 2s/step - loss: 0.1633 - accuracy: 0.9557 - val_loss: 0.2127 - val_accuracy: 0.9312\n",
            "Epoch 11/20\n",
            " 1/25 [>.............................] - ETA: 45s - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 00011: loss improved from 0.12258 to 0.02793, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:09 - loss: 0.0698 - accuracy: 0.9766\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            " 3/25 [==>...........................] - ETA: 51s - loss: 0.0794 - accuracy: 0.9740 \n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            " 4/25 [===>..........................] - ETA: 44s - loss: 0.0912 - accuracy: 0.9688\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            " 5/25 [=====>........................] - ETA: 40s - loss: 0.0979 - accuracy: 0.9663\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            " 6/25 [======>.......................] - ETA: 36s - loss: 0.1028 - accuracy: 0.9641\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            " 7/25 [=======>......................] - ETA: 33s - loss: 0.1077 - accuracy: 0.9622\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            " 8/25 [========>.....................] - ETA: 32s - loss: 0.1131 - accuracy: 0.9610\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            " 9/25 [=========>....................] - ETA: 30s - loss: 0.1202 - accuracy: 0.9596\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "10/25 [===========>..................] - ETA: 28s - loss: 0.1251 - accuracy: 0.9583\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "11/25 [============>.................] - ETA: 26s - loss: 0.1292 - accuracy: 0.9572\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "12/25 [=============>................] - ETA: 24s - loss: 0.1319 - accuracy: 0.9564\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "13/25 [==============>...............] - ETA: 22s - loss: 0.1349 - accuracy: 0.9557\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "14/25 [===============>..............] - ETA: 20s - loss: 0.1371 - accuracy: 0.9552\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "15/25 [=================>............] - ETA: 18s - loss: 0.1388 - accuracy: 0.9549\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "16/25 [==================>...........] - ETA: 16s - loss: 0.1404 - accuracy: 0.9545\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 0.1414 - accuracy: 0.9543\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.1422 - accuracy: 0.9541\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.1428 - accuracy: 0.9540\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.1431 - accuracy: 0.9540 \n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "21/25 [========================>.....] - ETA: 7s - loss: 0.1434 - accuracy: 0.9537\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1440 - accuracy: 0.9535\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1445 - accuracy: 0.9534\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1451 - accuracy: 0.9531\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9529\n",
            "Epoch 00011: loss did not improve from 0.02793\n",
            "25/25 [==============================] - 48s 2s/step - loss: 0.1462 - accuracy: 0.9526 - val_loss: 0.2254 - val_accuracy: 0.9438\n",
            "Epoch 12/20\n",
            " 1/25 [>.............................] - ETA: 45s - loss: 0.1692 - accuracy: 0.9062\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 2/25 [=>............................] - ETA: 38s - loss: 0.2228 - accuracy: 0.8906\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 3/25 [==>...........................] - ETA: 36s - loss: 0.2208 - accuracy: 0.8924\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 4/25 [===>..........................] - ETA: 34s - loss: 0.2181 - accuracy: 0.8939\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 5/25 [=====>........................] - ETA: 33s - loss: 0.2178 - accuracy: 0.8964\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 6/25 [======>.......................] - ETA: 31s - loss: 0.2272 - accuracy: 0.8954\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 7/25 [=======>......................] - ETA: 29s - loss: 0.2303 - accuracy: 0.8957\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 8/25 [========>.....................] - ETA: 28s - loss: 0.2296 - accuracy: 0.8975\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            " 9/25 [=========>....................] - ETA: 26s - loss: 0.2284 - accuracy: 0.8985\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "10/25 [===========>..................] - ETA: 25s - loss: 0.2273 - accuracy: 0.8995\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "11/25 [============>.................] - ETA: 24s - loss: 0.2249 - accuracy: 0.9012\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "12/25 [=============>................] - ETA: 22s - loss: 0.2225 - accuracy: 0.9027\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "13/25 [==============>...............] - ETA: 20s - loss: 0.2200 - accuracy: 0.9041\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "14/25 [===============>..............] - ETA: 18s - loss: 0.2173 - accuracy: 0.9054\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "15/25 [=================>............] - ETA: 17s - loss: 0.2147 - accuracy: 0.9065\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.2119 - accuracy: 0.9078\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "17/25 [===================>..........] - ETA: 13s - loss: 0.2093 - accuracy: 0.9092\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.2066 - accuracy: 0.9105\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.2040 - accuracy: 0.9119\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.2021 - accuracy: 0.9131 \n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.2001 - accuracy: 0.9142\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1981 - accuracy: 0.9153\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1963 - accuracy: 0.9163\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1944 - accuracy: 0.9173\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9183\n",
            "Epoch 00012: loss did not improve from 0.02793\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.1907 - accuracy: 0.9192 - val_loss: 0.1585 - val_accuracy: 0.9312\n",
            "Epoch 13/20\n",
            " 1/25 [>.............................] - ETA: 48s - loss: 0.0556 - accuracy: 0.9688\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 2/25 [=>............................] - ETA: 40s - loss: 0.0602 - accuracy: 0.9688\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 3/25 [==>...........................] - ETA: 38s - loss: 0.0715 - accuracy: 0.9688\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 4/25 [===>..........................] - ETA: 36s - loss: 0.0831 - accuracy: 0.9668\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 5/25 [=====>........................] - ETA: 34s - loss: 0.0887 - accuracy: 0.9659\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 6/25 [======>.......................] - ETA: 32s - loss: 0.0910 - accuracy: 0.9655\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 7/25 [=======>......................] - ETA: 31s - loss: 0.0921 - accuracy: 0.9654\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 8/25 [========>.....................] - ETA: 29s - loss: 0.0920 - accuracy: 0.9653\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            " 9/25 [=========>....................] - ETA: 27s - loss: 0.0927 - accuracy: 0.9641\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "10/25 [===========>..................] - ETA: 26s - loss: 0.0946 - accuracy: 0.9627\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "11/25 [============>.................] - ETA: 24s - loss: 0.0980 - accuracy: 0.9615\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "12/25 [=============>................] - ETA: 22s - loss: 0.1019 - accuracy: 0.9599\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "13/25 [==============>...............] - ETA: 21s - loss: 0.1046 - accuracy: 0.9589\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "14/25 [===============>..............] - ETA: 18s - loss: 0.1070 - accuracy: 0.9581\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "15/25 [=================>............] - ETA: 17s - loss: 0.1097 - accuracy: 0.9575\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.1117 - accuracy: 0.9570\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "17/25 [===================>..........] - ETA: 13s - loss: 0.1132 - accuracy: 0.9567\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.1142 - accuracy: 0.9566\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.1153 - accuracy: 0.9563\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.1168 - accuracy: 0.9559 \n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.1178 - accuracy: 0.9556\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1190 - accuracy: 0.9553\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1201 - accuracy: 0.9551\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1210 - accuracy: 0.9549\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9547\n",
            "Epoch 00013: loss did not improve from 0.02793\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.1233 - accuracy: 0.9544 - val_loss: 0.0939 - val_accuracy: 0.9688\n",
            "Epoch 14/20\n",
            " 1/25 [>.............................] - ETA: 48s - loss: 0.0999 - accuracy: 0.9688\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 2/25 [=>............................] - ETA: 39s - loss: 0.0852 - accuracy: 0.9766\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 3/25 [==>...........................] - ETA: 38s - loss: 0.0871 - accuracy: 0.9740\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 4/25 [===>..........................] - ETA: 36s - loss: 0.0972 - accuracy: 0.9707\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 5/25 [=====>........................] - ETA: 34s - loss: 0.1048 - accuracy: 0.9691\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 6/25 [======>.......................] - ETA: 32s - loss: 0.1090 - accuracy: 0.9681\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 7/25 [=======>......................] - ETA: 31s - loss: 0.1117 - accuracy: 0.9670\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 8/25 [========>.....................] - ETA: 29s - loss: 0.1147 - accuracy: 0.9662\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            " 9/25 [=========>....................] - ETA: 27s - loss: 0.1169 - accuracy: 0.9657\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "10/25 [===========>..................] - ETA: 25s - loss: 0.1182 - accuracy: 0.9657\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "11/25 [============>.................] - ETA: 24s - loss: 0.1183 - accuracy: 0.9660\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "12/25 [=============>................] - ETA: 22s - loss: 0.1184 - accuracy: 0.9660\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "13/25 [==============>...............] - ETA: 20s - loss: 0.1181 - accuracy: 0.9660\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "14/25 [===============>..............] - ETA: 18s - loss: 0.1185 - accuracy: 0.9657\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "15/25 [=================>............] - ETA: 17s - loss: 0.1187 - accuracy: 0.9655\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.1191 - accuracy: 0.9652\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "17/25 [===================>..........] - ETA: 13s - loss: 0.1199 - accuracy: 0.9648\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.1205 - accuracy: 0.9645\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.1208 - accuracy: 0.9643\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.1211 - accuracy: 0.9641 \n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.1211 - accuracy: 0.9641\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "22/25 [=========================>....] - ETA: 4s - loss: 0.1211 - accuracy: 0.9640\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1210 - accuracy: 0.9640\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1209 - accuracy: 0.9640\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9639\n",
            "Epoch 00014: loss did not improve from 0.02793\n",
            "25/25 [==============================] - 46s 2s/step - loss: 0.1212 - accuracy: 0.9639 - val_loss: 0.1018 - val_accuracy: 0.9812\n",
            "Epoch 15/20\n",
            " 1/25 [>.............................] - ETA: 51s - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 2/25 [=>............................] - ETA: 43s - loss: 0.0611 - accuracy: 0.9922\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 3/25 [==>...........................] - ETA: 40s - loss: 0.0772 - accuracy: 0.9844\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 4/25 [===>..........................] - ETA: 37s - loss: 0.0878 - accuracy: 0.9805\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 5/25 [=====>........................] - ETA: 35s - loss: 0.0903 - accuracy: 0.9794\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 6/25 [======>.......................] - ETA: 33s - loss: 0.1062 - accuracy: 0.9750\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 7/25 [=======>......................] - ETA: 31s - loss: 0.1144 - accuracy: 0.9728\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 8/25 [========>.....................] - ETA: 29s - loss: 0.1195 - accuracy: 0.9718\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            " 9/25 [=========>....................] - ETA: 28s - loss: 0.1230 - accuracy: 0.9711\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "10/25 [===========>..................] - ETA: 26s - loss: 0.1249 - accuracy: 0.9709\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "11/25 [============>.................] - ETA: 24s - loss: 0.1273 - accuracy: 0.9707\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "12/25 [=============>................] - ETA: 22s - loss: 0.1284 - accuracy: 0.9707\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "13/25 [==============>...............] - ETA: 20s - loss: 0.1289 - accuracy: 0.9708\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "14/25 [===============>..............] - ETA: 19s - loss: 0.1296 - accuracy: 0.9706\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "15/25 [=================>............] - ETA: 17s - loss: 0.1298 - accuracy: 0.9705\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.1304 - accuracy: 0.9703\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "17/25 [===================>..........] - ETA: 13s - loss: 0.1310 - accuracy: 0.9700\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.1319 - accuracy: 0.9696\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.1327 - accuracy: 0.9693\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.1337 - accuracy: 0.9690 \n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.1344 - accuracy: 0.9689\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1349 - accuracy: 0.9687\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1351 - accuracy: 0.9687\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1354 - accuracy: 0.9686\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9686\n",
            "Epoch 00015: loss did not improve from 0.02793\n",
            "25/25 [==============================] - 49s 2s/step - loss: 0.1355 - accuracy: 0.9687 - val_loss: 0.1203 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            " 1/25 [>.............................] - ETA: 1:34 - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 2/25 [=>............................] - ETA: 1:16 - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 3/25 [==>...........................] - ETA: 1:15 - loss: 0.0437 - accuracy: 1.0000\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 4/25 [===>..........................] - ETA: 1:10 - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 5/25 [=====>........................] - ETA: 59s - loss: 0.0482 - accuracy: 0.9962 \n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 6/25 [======>.......................] - ETA: 51s - loss: 0.0512 - accuracy: 0.9943\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 7/25 [=======>......................] - ETA: 45s - loss: 0.0542 - accuracy: 0.9919\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 8/25 [========>.....................] - ETA: 41s - loss: 0.0563 - accuracy: 0.9900\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            " 9/25 [=========>....................] - ETA: 37s - loss: 0.0602 - accuracy: 0.9884\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "10/25 [===========>..................] - ETA: 34s - loss: 0.0633 - accuracy: 0.9871\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "11/25 [============>.................] - ETA: 31s - loss: 0.0651 - accuracy: 0.9862\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "12/25 [=============>................] - ETA: 28s - loss: 0.0677 - accuracy: 0.9849\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "13/25 [==============>...............] - ETA: 25s - loss: 0.0694 - accuracy: 0.9841\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "14/25 [===============>..............] - ETA: 23s - loss: 0.0708 - accuracy: 0.9833\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "15/25 [=================>............] - ETA: 20s - loss: 0.0719 - accuracy: 0.9827\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "16/25 [==================>...........] - ETA: 18s - loss: 0.0739 - accuracy: 0.9820\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "17/25 [===================>..........] - ETA: 16s - loss: 0.0753 - accuracy: 0.9814\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "18/25 [====================>.........] - ETA: 14s - loss: 0.0778 - accuracy: 0.9808\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "19/25 [=====================>........] - ETA: 12s - loss: 0.0798 - accuracy: 0.9803\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "20/25 [=======================>......] - ETA: 9s - loss: 0.0814 - accuracy: 0.9800 \n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "21/25 [========================>.....] - ETA: 7s - loss: 0.0827 - accuracy: 0.9798\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.0842 - accuracy: 0.9794\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.0857 - accuracy: 0.9790\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.0869 - accuracy: 0.9787\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9784\n",
            "Epoch 00016: loss did not improve from 0.02793\n",
            "25/25 [==============================] - 54s 2s/step - loss: 0.0890 - accuracy: 0.9781 - val_loss: 0.2307 - val_accuracy: 0.9000\n",
            "Epoch 17/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 00017: loss improved from 0.02793 to 0.00615, saving model to ./base.model\n",
            "INFO:tensorflow:Assets written to: ./base.model/assets\n",
            " 2/25 [=>............................] - ETA: 1:17 - loss: 0.1507 - accuracy: 0.9688\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            " 3/25 [==>...........................] - ETA: 1:03 - loss: 0.1713 - accuracy: 0.9653\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            " 4/25 [===>..........................] - ETA: 53s - loss: 0.1859 - accuracy: 0.9583 \n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            " 5/25 [=====>........................] - ETA: 46s - loss: 0.1914 - accuracy: 0.9529\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            " 6/25 [======>.......................] - ETA: 42s - loss: 0.1901 - accuracy: 0.9512\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            " 7/25 [=======>......................] - ETA: 38s - loss: 0.1867 - accuracy: 0.9512\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            " 8/25 [========>.....................] - ETA: 35s - loss: 0.1871 - accuracy: 0.9499\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            " 9/25 [=========>....................] - ETA: 32s - loss: 0.1863 - accuracy: 0.9490\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "10/25 [===========>..................] - ETA: 30s - loss: 0.1862 - accuracy: 0.9475\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "11/25 [============>.................] - ETA: 27s - loss: 0.1857 - accuracy: 0.9466\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "12/25 [=============>................] - ETA: 25s - loss: 0.1845 - accuracy: 0.9460\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "13/25 [==============>...............] - ETA: 23s - loss: 0.1837 - accuracy: 0.9456\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "14/25 [===============>..............] - ETA: 21s - loss: 0.1826 - accuracy: 0.9453\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "15/25 [=================>............] - ETA: 19s - loss: 0.1818 - accuracy: 0.9449\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "16/25 [==================>...........] - ETA: 17s - loss: 0.1808 - accuracy: 0.9447\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "17/25 [===================>..........] - ETA: 15s - loss: 0.1795 - accuracy: 0.9446\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "18/25 [====================>.........] - ETA: 13s - loss: 0.1781 - accuracy: 0.9447\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "19/25 [=====================>........] - ETA: 11s - loss: 0.1766 - accuracy: 0.9449\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "20/25 [=======================>......] - ETA: 9s - loss: 0.1756 - accuracy: 0.9449 \n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "21/25 [========================>.....] - ETA: 7s - loss: 0.1744 - accuracy: 0.9451\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1733 - accuracy: 0.9453\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1720 - accuracy: 0.9455\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1711 - accuracy: 0.9456\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9457\n",
            "Epoch 00017: loss did not improve from 0.00615\n",
            "25/25 [==============================] - 49s 2s/step - loss: 0.1694 - accuracy: 0.9458 - val_loss: 0.1325 - val_accuracy: 0.9500\n",
            "Epoch 18/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.1384 - accuracy: 0.9375\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 2/25 [=>............................] - ETA: 38s - loss: 0.1435 - accuracy: 0.9453\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 3/25 [==>...........................] - ETA: 36s - loss: 0.1386 - accuracy: 0.9497\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 4/25 [===>..........................] - ETA: 35s - loss: 0.1340 - accuracy: 0.9525\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 5/25 [=====>........................] - ETA: 36s - loss: 0.1292 - accuracy: 0.9545\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 6/25 [======>.......................] - ETA: 35s - loss: 0.1251 - accuracy: 0.9560\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 7/25 [=======>......................] - ETA: 33s - loss: 0.1249 - accuracy: 0.9559\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 8/25 [========>.....................] - ETA: 30s - loss: 0.1245 - accuracy: 0.9556\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            " 9/25 [=========>....................] - ETA: 28s - loss: 0.1232 - accuracy: 0.9559\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "10/25 [===========>..................] - ETA: 26s - loss: 0.1213 - accuracy: 0.9565\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "11/25 [============>.................] - ETA: 24s - loss: 0.1191 - accuracy: 0.9574\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "12/25 [=============>................] - ETA: 21s - loss: 0.1171 - accuracy: 0.9581\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "13/25 [==============>...............] - ETA: 19s - loss: 0.1165 - accuracy: 0.9587\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "14/25 [===============>..............] - ETA: 18s - loss: 0.1159 - accuracy: 0.9593\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "15/25 [=================>............] - ETA: 16s - loss: 0.1160 - accuracy: 0.9595\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "16/25 [==================>...........] - ETA: 14s - loss: 0.1160 - accuracy: 0.9596\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "17/25 [===================>..........] - ETA: 13s - loss: 0.1165 - accuracy: 0.9595\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "18/25 [====================>.........] - ETA: 11s - loss: 0.1179 - accuracy: 0.9594\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.1195 - accuracy: 0.9593\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.1207 - accuracy: 0.9592 \n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.1215 - accuracy: 0.9592\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.1224 - accuracy: 0.9591\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.1231 - accuracy: 0.9591\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.1236 - accuracy: 0.9592\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9592\n",
            "Epoch 00018: loss did not improve from 0.00615\n",
            "25/25 [==============================] - 46s 2s/step - loss: 0.1242 - accuracy: 0.9593 - val_loss: 0.0591 - val_accuracy: 0.9750\n",
            "Epoch 19/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 2/25 [=>............................] - ETA: 38s - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 3/25 [==>...........................] - ETA: 37s - loss: 0.0563 - accuracy: 0.9931\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 4/25 [===>..........................] - ETA: 35s - loss: 0.0723 - accuracy: 0.9870\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 5/25 [=====>........................] - ETA: 33s - loss: 0.0784 - accuracy: 0.9846\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 6/25 [======>.......................] - ETA: 31s - loss: 0.0829 - accuracy: 0.9828\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 7/25 [=======>......................] - ETA: 30s - loss: 0.0853 - accuracy: 0.9821\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 8/25 [========>.....................] - ETA: 28s - loss: 0.0864 - accuracy: 0.9819\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            " 9/25 [=========>....................] - ETA: 26s - loss: 0.0868 - accuracy: 0.9820\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "10/25 [===========>..................] - ETA: 25s - loss: 0.0884 - accuracy: 0.9819\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "11/25 [============>.................] - ETA: 23s - loss: 0.0891 - accuracy: 0.9820\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "12/25 [=============>................] - ETA: 21s - loss: 0.0900 - accuracy: 0.9820\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "13/25 [==============>...............] - ETA: 20s - loss: 0.0906 - accuracy: 0.9817\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "14/25 [===============>..............] - ETA: 18s - loss: 0.0911 - accuracy: 0.9814\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "15/25 [=================>............] - ETA: 16s - loss: 0.0912 - accuracy: 0.9813\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.0910 - accuracy: 0.9812\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "17/25 [===================>..........] - ETA: 13s - loss: 0.0907 - accuracy: 0.9812\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "18/25 [====================>.........] - ETA: 11s - loss: 0.0905 - accuracy: 0.9811\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.0903 - accuracy: 0.9810\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.0900 - accuracy: 0.9809 \n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.0896 - accuracy: 0.9809\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.0894 - accuracy: 0.9809\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.0891 - accuracy: 0.9809\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.0888 - accuracy: 0.9808\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9807\n",
            "Epoch 00019: loss did not improve from 0.00615\n",
            "25/25 [==============================] - 44s 2s/step - loss: 0.0883 - accuracy: 0.9807 - val_loss: 0.1299 - val_accuracy: 0.9500\n",
            "Epoch 20/20\n",
            " 1/25 [>.............................] - ETA: 46s - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 2/25 [=>............................] - ETA: 38s - loss: 0.0462 - accuracy: 0.9844\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 3/25 [==>...........................] - ETA: 36s - loss: 0.0535 - accuracy: 0.9826\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 4/25 [===>..........................] - ETA: 35s - loss: 0.0551 - accuracy: 0.9831\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 5/25 [=====>........................] - ETA: 33s - loss: 0.0570 - accuracy: 0.9827\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 6/25 [======>.......................] - ETA: 31s - loss: 0.0574 - accuracy: 0.9830\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 7/25 [=======>......................] - ETA: 30s - loss: 0.0616 - accuracy: 0.9816\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 8/25 [========>.....................] - ETA: 29s - loss: 0.0650 - accuracy: 0.9800\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            " 9/25 [=========>....................] - ETA: 28s - loss: 0.0666 - accuracy: 0.9791\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "10/25 [===========>..................] - ETA: 26s - loss: 0.0674 - accuracy: 0.9787\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "11/25 [============>.................] - ETA: 24s - loss: 0.0703 - accuracy: 0.9778\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "12/25 [=============>................] - ETA: 22s - loss: 0.0741 - accuracy: 0.9768\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "13/25 [==============>...............] - ETA: 21s - loss: 0.0767 - accuracy: 0.9762\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "14/25 [===============>..............] - ETA: 19s - loss: 0.0785 - accuracy: 0.9758\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "15/25 [=================>............] - ETA: 17s - loss: 0.0796 - accuracy: 0.9756\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "16/25 [==================>...........] - ETA: 15s - loss: 0.0805 - accuracy: 0.9756\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "17/25 [===================>..........] - ETA: 14s - loss: 0.0812 - accuracy: 0.9754\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "18/25 [====================>.........] - ETA: 12s - loss: 0.0817 - accuracy: 0.9752\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "19/25 [=====================>........] - ETA: 10s - loss: 0.0822 - accuracy: 0.9750\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "20/25 [=======================>......] - ETA: 8s - loss: 0.0827 - accuracy: 0.9749 \n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "21/25 [========================>.....] - ETA: 6s - loss: 0.0833 - accuracy: 0.9747\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "22/25 [=========================>....] - ETA: 5s - loss: 0.0841 - accuracy: 0.9743\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "23/25 [==========================>...] - ETA: 3s - loss: 0.0848 - accuracy: 0.9740\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "24/25 [===========================>..] - ETA: 1s - loss: 0.0853 - accuracy: 0.9738\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9736\n",
            "Epoch 00020: loss did not improve from 0.00615\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.0860 - accuracy: 0.9734 - val_loss: 0.1407 - val_accuracy: 0.9625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIAjtyAGgSHg"
      },
      "source": [
        "#Function To Make Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yuj9JOp50cs"
      },
      "source": [
        "def graph(history):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
        "    ax[0].set_title('loss')\n",
        "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
        "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
        "    ax[1].set_title('acc')\n",
        "    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train acc\")\n",
        "    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation acc\")\n",
        "    ax[0].legend()\n",
        "    ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "uBosSJOR51_6",
        "outputId": "645b740d-2c37-4973-c934-d26a507dcd6b"
      },
      "source": [
        "graph(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNEcDE1C9zw1"
      },
      "source": [
        "#Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdkxsgow59Ek",
        "outputId": "bd7dd2e4-0e3b-430d-8b71-1feda919b0aa"
      },
      "source": [
        "model_score = model.evaluate(validation_generator,steps=25)\n",
        "print(\"Model Test Loss:\",model_score[0])\n",
        "print(\"Model Test Accuracy:\",model_score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 16s 638ms/step - loss: 0.0995 - accuracy: 0.9688\n",
            "Model Test Loss: 0.09952306002378464\n",
            "Model Test Accuracy: 0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of0BGS0ogd8n"
      },
      "source": [
        "#Predict Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "YD3gI4kk5-3R",
        "outputId": "aa84f910-c5ae-4cde-fc6e-4135576f979e"
      },
      "source": [
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict_classes(images, batch_size=10)\n",
        "  \n",
        "  print(fn)\n",
        "  print(classes)\n",
        "\n",
        "  if classes==0:\n",
        "    print('Paper')\n",
        "  elif classes==1:\n",
        "    print('Rock')\n",
        "  elif classes==2:\n",
        "    print('Scissor')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d87b1677-a8c7-46fd-9fb4-c622ea1ad4d2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d87b1677-a8c7-46fd-9fb4-c622ea1ad4d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving scissor.png to scissor (1).png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "scissor.png\n",
            "[2]\n",
            "Scissor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}